                String Tokenization             by FC 2017-01-05

In lexical analysis, tokenization is the process of breaking a stream of text up into words, phrases, symbols, or other meaningful elements called tokens. The list of tokens becomes input for further processing such as parsing or text mining. Tokenization is useful both in linguistics (where it is a form of text segmentation), and in computer science, where it forms part of lexical analysis.

Methods and obstacles
Typically, tokenization occurs at the word level. However, it is sometimes difficult to define what is meant by a "word". Often a tokenizer relies on simple heuristics, for example:
Punctuation and whitespace may or may not be included in the resulting list of tokens.
All contiguous strings of alphabetic characters are part of one token; likewise with numbers
Tokens are separated by whitespace characters, such as a space or line break, or by punctuation characters.
In languages that use inter-word spaces (such as most that use the Latin alphabet, and most programming languages), this approach is fairly straightforward. However, even here there are many edge cases such as contractions, hyphenated words, emoticons, and larger constructs such as URIs (which for some purposes may count as single tokens). A classic example is "New York-based", which a naive tokenizer may break at the space even though the better break is (arguably) at the hyphen.
Tokenization is particularly difficult for languages written in scriptio continua which exhibit no word boundaries such as Ancient Greek, Chinese,[1] or Thai. Agglutinative language, such as Korean, also make tokenization tasks complicated.
Some ways to address the more difficult problems include developing more complex heuristics, querying a table of common special-cases, or fitting the tokens to a language model that identifies collocations in a later processing step.


//      -- java.util.StringTokenizer in JDK 1.8.0_51 --
package java.util;
import java.lang.*;

/** The string tokenizer class allows an application to break a string into tokens.
 * The tokenization method is much simpler than the one used by the StreamTokenizer class. 
 * The StringTokenizer methods do not distinguish among identifiers, numbers, and quoted 
 * strings, nor do they recognize and skip comments.
 * The set of delimiters (the characters that separate tokens) may be specified either at 
 * creation time or on a per-token basis.
 * 
 * An instance of StringTokenizer behaves in one of two ways, depending on whether it was 
 * created with the returnDelims flag having the value true or false:
 * 
 * If the flag is false, delimiter characters serve to separate tokens. A token is a maximal 
 * sequence of consecutive characters that are not delimiters.
 * If the flag is true, delimiter characters are themselves considered to be tokens. A token
 * is thus either one delimiter character, or a maximal sequence of consecutive characters 
 * that are not delimiters.
 * A StringTokenizer object internally maintains a current position within the string to be
 * tokenized. Some operations advance this current position past the characters processed.
 * 
 * A token is returned by taking a substring of the string that was used to create the 
 * StringTokenizer object.
 * 
 * The following is one example of the use of the tokenizer. The code:
 *      StringTokenizer st = new StringTokenizer("this is a test");
 *      while (st.hasMoreTokens()) {
 *          System.out.println(st.nextToken());
 *      }
 *  
 * prints the following output:
 *      this
 *      is
 *      a
 *      test
 *  
 * StringTokenizer is a legacy class that is retained for compatibility reasons although its
 * use is discouraged in new code. It is recommended that anyone seeking this functionality
 * use the split method of String or the java.util.regex package instead.
 * 
 * The following example illustrates how the String.split method can be used to break up a 
 * string into its basic tokens:
 *      String[] result = "this is a test".split("\\s");
 *      for (int x=0; x<result.length; x++)
 *          System.out.println(result[x]);
 * prints the following output:
 *      this
 *      is
 *      a
 *      test
 * @see     java.io.StreamTokenizer
 * @since   JDK1.0
 */
public class StringTokenizer implements Enumeration<Object> {
    private int currentPosition;
    private int newPosition;
    private int maxPosition;
    private String str;
    private String delimiters;
    private boolean retDelims;
    private boolean delimsChanged;

    /**
     * Constructs a string tokenizer for the specified string. All
     * characters in the <code>delim</code> argument are the delimiters
     * for separating tokens.
     * If the <code>returnDelims</code> flag is <code>true</code>, then
     * the delimiter characters are also returned as tokens. Each
     * delimiter is returned as a string of length one. If the flag is
     * <code>false</code>, the delimiter characters are skipped and only
     * serve as separators between tokens.
     * Note that if <tt>delim</tt> is <tt>null</tt>, this constructor does
     * not throw an exception. However, trying to invoke other methods on the
     * resulting <tt>StringTokenizer</tt> may result in a
     * <tt>NullPointerException</tt>.  */
    public StringTokenizer(String str, String delim, boolean returnDelims) {
        currentPosition = 0;
        newPosition = -1;
        delimsChanged = false;
        this.str = str;
        maxPosition = str.length();
        delimiters = delim;
        retDelims = returnDelims;
        setMaxDelimCodePoint();
    }
    public StringTokenizer(String str, String delim)    { this(str, delim, false); }
    public StringTokenizer(String str)                  { this(str, " \t\n\r\f", false); }

    /** Tests if there are more tokens available from this tokenizer's string.
     * If this method returns <tt>true</tt>, then a subsequent call to
     * <tt>nextToken</tt> with no argument will successfully return a token.
     * @return  true if and only if there is at least one token
     *          in the string after the current position; false otherwise. */
    public boolean hasMoreTokens() {
        /* Temporarily store this position and use it in the following
         * nextToken() method only if the delimiters haven't been changed in
         * that nextToken() invocation. */
        newPosition = skipDelimiters(currentPosition);
        return (newPosition < maxPosition);
    }

    /** Returns the next token from this string tokenizer.
     * @return     the next token from this string tokenizer.
     * @exception  NoSuchElementException  if no more tokens in this tokenizer's string. */
    public String nextToken() {
        /* If next position already computed in hasMoreElements() and
         * delimiters have changed between the computation and this invocation,
         * then use the computed value.  */
        currentPosition = (newPosition >= 0 && !delimsChanged) ?
            newPosition : skipDelimiters(currentPosition);

        /* Reset these anyway */
        delimsChanged = false;
        newPosition = -1;

        if (currentPosition >= maxPosition)
            throw new NoSuchElementException();
        int start = currentPosition;
        currentPosition = scanToken(currentPosition);
        return str.substring(start, currentPosition);
    }

    /** Returns the next token in this string tokenizer's string. First,
     * the set of characters considered to be delimiters by this
     * <tt>StringTokenizer</tt> object is changed to be the characters in
     * the string <tt>delim</tt>. Then the next token in the string
     * after the current position is returned. The current position is
     * advanced beyond the recognized token.  The new delimiter set
     * remains the default after this call.
     * @param      delim   the new delimiters.
     * @return     the next token, after switching to the new delimiter set. */
    public String nextToken(String delim) {
        delimiters = delim;
        /* delimiter string specified, so set the appropriate flag. */
        delimsChanged = true;
        setMaxDelimCodePoint();
        return nextToken();
    }

    // -- Enumeration --
    public boolean hasMoreElements() { return hasMoreTokens(); }
    public Object nextElement() { return nextToken(); }

    /** Calculates the number of times that this tokenizer's
     * <code>nextToken</code> method can be called before it generates an
     * exception. The current position is not advanced.
     * @return  the number of tokens remaining in the string using the current delimiter set. */
    public int countTokens() {
        int count = 0;
        int currpos = currentPosition;
        while (currpos < maxPosition) {
            currpos = skipDelimiters(currpos);
            if (currpos >= maxPosition)
                break;
            currpos = scanToken(currpos);
            count++;
        }
        return count;
    }

    /** Skips delimiters starting from the specified position. If retDelims
     * is false, returns the index of the first non-delimiter character at or
     * after startPos. If retDelims is true, startPos is returned. */
    private int skipDelimiters(int startPos) {
        if (delimiters == null)
            throw new NullPointerException();

        int position = startPos;
        while (!retDelims && position < maxPosition) {
            if (!hasSurrogates) {
                char c = str.charAt(position);
                if ((c > maxDelimCodePoint) || (delimiters.indexOf(c) < 0))
                    break;
                position++;
            } else {
                int c = str.codePointAt(position);
                if ((c > maxDelimCodePoint) || !isDelimiter(c)) {
                    break;
                }
                position += Character.charCount(c);
            }
        }
        return position;
    }

    /** Skips ahead from startPos and returns the index of the next delimiter
     * character encountered, or maxPosition if no such delimiter is found.  */
    private int scanToken(int startPos) {
        int position = startPos;
        while (position < maxPosition) {
            if (!hasSurrogates) {
                char c = str.charAt(position);
                if ((c <= maxDelimCodePoint) && (delimiters.indexOf(c) >= 0))
                    break;
                position++;
            } else {
                int c = str.codePointAt(position);
                if ((c <= maxDelimCodePoint) && isDelimiter(c))
                    break;
                position += Character.charCount(c);
            }
        }
        if (retDelims && (startPos == position)) {
            if (!hasSurrogates) {
                char c = str.charAt(position);
                if ((c <= maxDelimCodePoint) && (delimiters.indexOf(c) >= 0))
                    position++;
            } else {
                int c = str.codePointAt(position);
                if ((c <= maxDelimCodePoint) && isDelimiter(c))
                    position += Character.charCount(c);
            }
        }
        return position;
    }

    private boolean isDelimiter(int codePoint) {
        for (int i = 0; i < delimiterCodePoints.length; i++) {
            if (delimiterCodePoints[i] == codePoint) {
                return true;
            }
        }
        return false;
    }

    /** maxDelimCodePoint stores the value of the delimiter character with the
     * highest value. It is used to optimize the detection of delimiter
     * characters.
     * It is unlikely to provide any optimization benefit in the
     * hasSurrogates case because most string characters will be
     * smaller than the limit, but we keep it so that the two code
     * paths remain similar.  */
    private int maxDelimCodePoint;

    /** If delimiters include any surrogates (including surrogate
     * pairs), hasSurrogates is true and the tokenizer uses the
     * different code path. This is because String.indexOf(int)
     * doesn't handle unpaired surrogates as a single character.  */
    private boolean hasSurrogates = false;

    /** When hasSurrogates is true, delimiters are converted to code
     * points and isDelimiter(int) is used to determine if the given
     * codepoint is a delimiter.  */
    private int[] delimiterCodePoints;

    /** Set maxDelimCodePoint to the highest char in the delimiter set. */
    private void setMaxDelimCodePoint() {
        if (delimiters == null) {
            maxDelimCodePoint = 0;
            return;
        }

        int m = 0;
        int c;
        int count = 0;
        for (int i = 0; i < delimiters.length(); i += Character.charCount(c)) {
            c = delimiters.charAt(i);
            if (c >= Character.MIN_HIGH_SURROGATE && c <= Character.MAX_LOW_SURROGATE) {
                c = delimiters.codePointAt(i);
                hasSurrogates = true;
            }
            if (m < c)
                m = c;
            count++;
        }
        maxDelimCodePoint = m;

        if (hasSurrogates) {
            delimiterCodePoints = new int[count];
            for (int i = 0, j = 0; i < count; i++, j += Character.charCount(c)) {
                c = delimiters.codePointAt(j);
                delimiterCodePoints[i] = c;
            }
        }
    }
}

//      -- java.io.StreamTokenizer in JDK 1.8.0_51 --
package java.io;
import java.util.Arrays;

/**
 * The StreamTokenizer class takes an input stream and parses it into "tokens", allowing the
 * tokens to be read one at a time. The parsing process is controlled by a table and a number
 * of flags that can be set to various states. The stream tokenizer can recognize identifiers,
 * numbers, quoted strings, and various comment styles.
 * Each byte read from the input stream is regarded as a character in the range '\u0000' 
 * through '\u00FF'. The character value is used to look up five possible attributes of the 
 * character: white space, alphabetic, numeric, string quote, and comment character. 
 * Each character can have zero or more of these attributes.
 * In addition, an instance has four flags. These flags indicate:
 * - Whether line terminators are to be returned as tokens or treated as white space that merely separates tokens.
 * - Whether C-style comments are to be recognized and skipped.
 * - Whether C++-style comments are to be recognized and skipped.
 * - Whether the characters of identifiers are converted to lowercase.
 * A typical application first constructs an instance of this class, sets up the syntax tables,
 * and then repeatedly loops calling the nextToken method in each iteration of the loop until
 * it returns the value TT_EOF.
 * @since   JDK1.0 */
public class StreamTokenizer {
    private Reader reader = null;    /* Only one of these will be non-null */
    private InputStream input = null;
    private char buf[] = new char[20];

    /** The next character to be considered by the nextToken method.  May also
     * be NEED_CHAR to indicate that a new character should be read, or SKIP_LF
     * to indicate that a new character should be read and, if it is a '\n'
     * character, it should be discarded and a second new character should be read. */
    private int peekc = NEED_CHAR;
    private static final int NEED_CHAR = Integer.MAX_VALUE;
    private static final int SKIP_LF = Integer.MAX_VALUE - 1;

    private boolean pushedBack;
    private boolean forceLower;
    private int LINENO = 1;    /** The line number of the last token read */

    private boolean eolIsSignificantP = false;    // whether ends of line are treated as tokens
    private boolean slashSlashCommentsP = false;  // whether recognizes C++-style comments
    private boolean slashStarCommentsP = false;   // whether recognizes C-style comments

    private byte ctype[] = new byte[256];
    private static final byte CT_WHITESPACE = 1;
    private static final byte CT_DIGIT = 2;
    private static final byte CT_ALPHA = 4;
    private static final byte CT_QUOTE = 8;
    private static final byte CT_COMMENT = 16;

    /** After a call to the {@code nextToken} method, this field
     * contains the type of the token just read. For a single character
     * token, its value is the single character, converted to an integer.
     * For a quoted string token, its value is the quote character.
     * Otherwise, its value is one of the following:
     *  - TT_WORD indicates that the token is a word.
     *  - TT_NUMBER indicates that the token is a number.
     *  - TT_EOL indicates that the end of line has been read. The field can only have this
     *    value if the eolIsSignificant method has been called with the argument true.
     *  - TT_EOF indicates that the end of the input stream has been reached.
     * The initial value of this field is -4. */
    public int ttype = TT_NOTHING;

    /* A constant indicating that no token has been read, used for
     * initializing ttype.  FIXME This could be made public and
     * made available as the part of the API in a future release. */
    private static final int TT_NOTHING = -4;
    public static final int TT_EOF = -1;        // end of file
    public static final int TT_EOL = '\n';      // end of line
    public static final int TT_NUMBER = -2;     // number
    public static final int TT_WORD = -3;       // word

    /** If the current token is a word token, this field contains a
     * string giving the characters of the word token. When the current
     * token is a quoted string token, this field contains the body of
     * the string.
     * The current token is a word when the value of the
     * {@code ttype} field is {@code TT_WORD}. The current token is
     * a quoted string token when the value of the {@code ttype} field is
     * a quote character.
     * The initial value of this field is null. */
    public String sval;

    /** If the current token is a number, this field contains the value
     * of that number. The current token is a number when the value of
     * the {@code ttype} field is {@code TT_NUMBER}.
     * The initial value of this field is 0.0. */
    public double nval;

    /** Private constructor that initializes everything except the streams. */
    private StreamTokenizer() {
        wordChars('a', 'z');
        wordChars('A', 'Z');
        wordChars(128 + 32, 255);
        whitespaceChars(0, ' ');
        commentChar('/');
        quoteChar('"');
        quoteChar('\'');
        parseNumbers();
    }

    public StreamTokenizer(Reader r) {
        this();
        if (r == null) { throw new NullPointerException(); }
        reader = r;
    }

    /** Resets this tokenizer's syntax table so that all characters are "ordinary."
     * See the ordinaryChar method for more information on a character being ordinary. */
    public void resetSyntax() {
        for (int i = ctype.length; --i >= 0;)
            ctype[i] = 0;
    }

    /** Specifies that all characters c in the range (low,high) are word constituents.  */
    public void wordChars(int low, int hi) {
        if (low < 0)
            low = 0;
        if (hi >= ctype.length)
            hi = ctype.length - 1;
        while (low <= hi)
            ctype[low++] |= CT_ALPHA;
    }

    public void whitespaceChars(int low, int hi) {
        if (low < 0)
            low = 0;
        if (hi >= ctype.length)
            hi = ctype.length - 1;
        while (low <= hi)
            ctype[low++] = CT_WHITESPACE;
    }

    public void ordinaryChars(int low, int hi) {
        if (low < 0)
            low = 0;
        if (hi >= ctype.length)
            hi = ctype.length - 1;
        while (low <= hi)
            ctype[low++] = 0;
    }

    /** Specifies that the character argument is "ordinary" in this tokenizer. 
     * It removes any special significance the character has as a comment character,
     * word component, string delimiter, white space, or number character.
     * When such a character is encountered by the parser, the parser treats it as a
     * single-character token and sets {@code ttype} field to the character value.
     * Making a line terminator character "ordinary" may interfere with the ability
     * of a StreamTokenizer to count lines. The lineno method may no longer reflect
     * the presence of such terminator characters in its line count. */
    public void ordinaryChar(int ch) {
        if (ch >= 0 && ch < ctype.length)
            ctype[ch] = 0;
    }

    public void commentChar(int ch) {
        if (ch >= 0 && ch < ctype.length)
            ctype[ch] = CT_COMMENT;
    }

    public void quoteChar(int ch) {
        if (ch >= 0 && ch < ctype.length)
            ctype[ch] = CT_QUOTE;
    }

    public void parseNumbers() {
        for (int i = '0'; i <= '9'; i++)
            ctype[i] |= CT_DIGIT;
        ctype['.'] |= CT_DIGIT;
        ctype['-'] |= CT_DIGIT;
    }

    public void eolIsSignificant(boolean flag)          { eolIsSignificantP = flag; }
    public void slashStarComments(boolean flag)         { slashStarCommentsP = flag; }
    public void slashSlashComments(boolean flag)        { slashSlashCommentsP = flag; }
    public void lowerCaseMode(boolean fl)               { forceLower = fl; }

    /** Read the next character */
    private int read() throws IOException {
        if (reader != null)
            return reader.read();
        else if (input != null)
            return input.read();
        else
            throw new IllegalStateException();
    }

    /** Parses the next token from the input stream of this tokenizer.
     * The type of the next token is returned in the ttype field. 
     * Additional information about the token may be in the nval field or the sval field.
     * Typical clients of this class first set up the syntax tables and then sit in a loop
     * calling nextToken to parse successive tokens until TT_EOF is returned.
     * @return     the value of the ttype field.  */
    public int nextToken() throws IOException {
        if (pushedBack) {
            pushedBack = false;
            return ttype;
        }
        byte ct[] = ctype;
        sval = null;

        int c = peekc;
        if (c < 0)
            c = NEED_CHAR;
        if (c == SKIP_LF) {
            c = read();
            if (c < 0)
                return ttype = TT_EOF;
            if (c == '\n')
                c = NEED_CHAR;
        }
        if (c == NEED_CHAR) {
            c = read();
            if (c < 0)
                return ttype = TT_EOF;
        }
        ttype = c;              /* Just to be safe */

        /* Set peekc so that the next invocation of nextToken will read
         * another character unless peekc is reset in this invocation
         */
        peekc = NEED_CHAR;

        int ctype = c < 256 ? ct[c] : CT_ALPHA;
        while ((ctype & CT_WHITESPACE) != 0) {
            if (c == '\r') {
                LINENO++;
                if (eolIsSignificantP) {
                    peekc = SKIP_LF;
                    return ttype = TT_EOL;
                }
                c = read();
                if (c == '\n')
                    c = read();
            } else {
                if (c == '\n') {
                    LINENO++;
                    if (eolIsSignificantP) {
                        return ttype = TT_EOL;
                    }
                }
                c = read();
            }
            if (c < 0)
                return ttype = TT_EOF;
            ctype = c < 256 ? ct[c] : CT_ALPHA;
        }

        if ((ctype & CT_DIGIT) != 0) {
            boolean neg = false;
            if (c == '-') {
                c = read();
                if (c != '.' && (c < '0' || c > '9')) {
                    peekc = c;
                    return ttype = '-';
                }
                neg = true;
            }
            double v = 0;
            int decexp = 0;
            int seendot = 0;
            while (true) {
                if (c == '.' && seendot == 0)
                    seendot = 1;
                else if ('0' <= c && c <= '9') {
                    v = v * 10 + (c - '0');
                    decexp += seendot;
                } else
                    break;
                c = read();
            }
            peekc = c;
            if (decexp != 0) {
                double denom = 10;
                decexp--;
                while (decexp > 0) {
                    denom *= 10;
                    decexp--;
                }
                /* Do one division of a likely-to-be-more-accurate number */
                v = v / denom;
            }
            nval = neg ? -v : v;
            return ttype = TT_NUMBER;
        }

        if ((ctype & CT_ALPHA) != 0) {
            int i = 0;
            do {
                if (i >= buf.length) {
                    buf = Arrays.copyOf(buf, buf.length * 2);
                }
                buf[i++] = (char) c;
                c = read();
                ctype = c < 0 ? CT_WHITESPACE : c < 256 ? ct[c] : CT_ALPHA;
            } while ((ctype & (CT_ALPHA | CT_DIGIT)) != 0);
            peekc = c;
            sval = String.copyValueOf(buf, 0, i);
            if (forceLower)
                sval = sval.toLowerCase();
            return ttype = TT_WORD;
        }

        if ((ctype & CT_QUOTE) != 0) {
            ttype = c;
            int i = 0;
            /* Invariants (because \Octal needs a lookahead):
             *   (i)  c contains char value
             *   (ii) d contains the lookahead
             */
            int d = read();
            while (d >= 0 && d != ttype && d != '\n' && d != '\r') {
                if (d == '\\') {
                    c = read();
                    int first = c;   /* To allow \377, but not \477 */
                    if (c >= '0' && c <= '7') {
                        c = c - '0';
                        int c2 = read();
                        if ('0' <= c2 && c2 <= '7') {
                            c = (c << 3) + (c2 - '0');
                            c2 = read();
                            if ('0' <= c2 && c2 <= '7' && first <= '3') {
                                c = (c << 3) + (c2 - '0');
                                d = read();
                            } else
                                d = c2;
                        } else
                          d = c2;
                    } else {
                        switch (c) {
                        case 'a': c = 0x7; break;
                        case 'b': c = '\b'; break;
                        case 'f': c = 0xC; break;
                        case 'n': c = '\n'; break;
                        case 'r': c = '\r'; break;
                        case 't': c = '\t'; break;
                        case 'v': c = 0xB; break;
                        }
                        d = read();
                    }
                } else {
                    c = d;
                    d = read();
                }
                if (i >= buf.length) {
                    buf = Arrays.copyOf(buf, buf.length * 2);
                }
                buf[i++] = (char)c;
            }

            /* If we broke out of the loop because we found a matching quote
             * character then arrange to read a new character next time
             * around; otherwise, save the character.
             */
            peekc = (d == ttype) ? NEED_CHAR : d;

            sval = String.copyValueOf(buf, 0, i);
            return ttype;
        }

        if (c == '/' && (slashSlashCommentsP || slashStarCommentsP)) {
            c = read();
            if (c == '*' && slashStarCommentsP) {
                int prevc = 0;
                while ((c = read()) != '/' || prevc != '*') {
                    if (c == '\r') {
                        LINENO++;
                        c = read();
                        if (c == '\n') {
                            c = read();
                        }
                    } else {
                        if (c == '\n') {
                            LINENO++;
                            c = read();
                        }
                    }
                    if (c < 0)
                        return ttype = TT_EOF;
                    prevc = c;
                }
                return nextToken();
            } else if (c == '/' && slashSlashCommentsP) {
                while ((c = read()) != '\n' && c != '\r' && c >= 0);
                peekc = c;
                return nextToken();
            } else {
                /* Now see if it is still a single line comment */
                if ((ct['/'] & CT_COMMENT) != 0) {
                    while ((c = read()) != '\n' && c != '\r' && c >= 0);
                    peekc = c;
                    return nextToken();
                } else {
                    peekc = c;
                    return ttype = '/';
                }
            }
        }

        if ((ctype & CT_COMMENT) != 0) {
            while ((c = read()) != '\n' && c != '\r' && c >= 0);
            peekc = c;
            return nextToken();
        }

        return ttype = c;
    }

    /** Causes the next call to the {@code nextToken} method of this
     * tokenizer to return the current value in the {@code ttype}
     * field, and not to modify the value in the nval} or sval field.  */
    public void pushBack() {
        if (ttype != TT_NOTHING)   /* No-op if nextToken() not called */
            pushedBack = true;
    }

    public int lineno() { return LINENO; }
}

//      -- StrTokenizer in Apache Common Language 2.4 --
package org.apache.commons.lang.text;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.ListIterator;
import java.util.NoSuchElementException;

/** Tokenizes a string based based on delimiters (separators) and supporting quoting and 
 * ignored character concepts. 
 * This class can split a String into many smaller strings. It aims to do a similar job to
 * StringTokenizer, however it offers much more control and flexibility including implementing
 * the ListIterator interface. By default, it is set up like StringTokenizer. 
 * The input String is split into a number of tokens. Each token is separated from the next
 * String by a delimiter. One or more delimiter characters must be specified. 
 * Each token may be surrounded by quotes. The quote matcher specifies the quote character(s).
 * A quote may be escaped within a quoted section by duplicating itself. 
 * Between each token and the delimiter are potentially characters that need trimming. The 
 * trimmer matcher specifies these characters. One usage might be to trim whitespace characters. 
 * At any point outside the quotes there might potentially be invalid characters. The ignored
 * matcher specifies these characters to be removed. One usage might be to remove new line 
 * characters. 
 * Empty tokens may be removed or returned as null. 
 *      "a,b,c"         - Three tokens "a","b","c"   (comma delimiter)
 *      " a, b , c "    - Three tokens "a","b","c"   (default CSV processing trims whitespace)
 *      "a, ", b ,", c" - Three tokens "a, " , " b ", ", c" (quoted text untouched)
 * This tokenizer has the following properties and options: 
 *      Property Type Default 
 *      delim CharSetMatcher { \t\n\r\f} 
 *      quote NoneMatcher {} 
 *      ignore NoneMatcher {} 
 *      emptyTokenAsNull boolean false 
 *      ignoreEmptyTokens boolean true 
 */
public class StrTokenizer implements ListIterator, Cloneable {
    private static final StrTokenizer CSV_TOKENIZER_PROTOTYPE;
    private static final StrTokenizer TSV_TOKENIZER_PROTOTYPE;
    static {
        CSV_TOKENIZER_PROTOTYPE = new StrTokenizer();
        CSV_TOKENIZER_PROTOTYPE.setDelimiterMatcher(StrMatcher.commaMatcher());
        CSV_TOKENIZER_PROTOTYPE.setQuoteMatcher(StrMatcher.doubleQuoteMatcher());
        CSV_TOKENIZER_PROTOTYPE.setIgnoredMatcher(StrMatcher.noneMatcher());
        CSV_TOKENIZER_PROTOTYPE.setTrimmerMatcher(StrMatcher.trimMatcher());
        CSV_TOKENIZER_PROTOTYPE.setEmptyTokenAsNull(false);
        CSV_TOKENIZER_PROTOTYPE.setIgnoreEmptyTokens(false);

        TSV_TOKENIZER_PROTOTYPE = new StrTokenizer();
        TSV_TOKENIZER_PROTOTYPE.setDelimiterMatcher(StrMatcher.tabMatcher());
        TSV_TOKENIZER_PROTOTYPE.setQuoteMatcher(StrMatcher.doubleQuoteMatcher());
        TSV_TOKENIZER_PROTOTYPE.setIgnoredMatcher(StrMatcher.noneMatcher());
        TSV_TOKENIZER_PROTOTYPE.setTrimmerMatcher(StrMatcher.trimMatcher());
        TSV_TOKENIZER_PROTOTYPE.setEmptyTokenAsNull(false);
        TSV_TOKENIZER_PROTOTYPE.setIgnoreEmptyTokens(false);
    }

    private char chars[];    /** The text to work on. */
    private String tokens[]; /** The parsed tokens */
    private int tokenPos;    /** The current iteration position */

    private StrMatcher delimMatcher = StrMatcher.splitMatcher();
    private StrMatcher quoteMatcher = StrMatcher.noneMatcher();
    private StrMatcher ignoredMatcher = StrMatcher.noneMatcher();
    private StrMatcher trimmerMatcher = StrMatcher.noneMatcher();

    private boolean emptyAsNull = false;    /** Whether to return empty tokens as null */
    private boolean ignoreEmptyTokens = true;    /** Whether to ignore empty tokens */

    /** Gets a new tokenizer instance which parses Comma Separated Value strings
     * initializing it with the given input.  The default for CSV processing
     * will be trim whitespace from both ends (which can be overridden with
     * the setTrimmer method).
     * You must call a "reset" method to set the string which you want to parse.
     * @return a new tokenizer instance which parses Comma Separated Value strings */
    public static StrTokenizer getCSVInstance() { return getCSVClone(); }
    public static StrTokenizer getCSVInstance(String input) { StrTokenizer tok = getCSVClone(); tok.reset(input); return tok; }
    public static StrTokenizer getCSVInstance(char[] input) { StrTokenizer tok = getCSVClone(); tok.reset(input); return tok; }
    private static StrTokenizer getCSVClone() {
        return (StrTokenizer) CSV_TOKENIZER_PROTOTYPE.clone();
    }

    /** Gets a new tokenizer instance which parses Tab Separated Value strings.
     * The default for CSV processing will be trim whitespace from both ends
     * (which can be overridden with the setTrimmer method).
     * You must call a "reset" method to set the string which you want to parse.
     * @return a new tokenizer instance which parses Tab Separated Value strings. */
    public static StrTokenizer getTSVInstance() { return getTSVClone(); }
    public static StrTokenizer getTSVInstance(String input) { StrTokenizer tok = getTSVClone(); tok.reset(input); return tok; }
    public static StrTokenizer getTSVInstance(char[] input) { StrTokenizer tok = getTSVClone(); tok.reset(input); return tok; }
    private static StrTokenizer getTSVClone() {
        return (StrTokenizer) TSV_TOKENIZER_PROTOTYPE.clone();
    }

    /** Constructs a tokenizer splitting on space, tab, newline and formfeed
     * as per StringTokenizer, but with no text to tokenize.  */
    public StrTokenizer() { super(); this.chars = null; }
    public StrTokenizer(String input) { super(); chars = input != null ? input.toCharArray() : null; }
    public StrTokenizer(String input, char delim)       { this(input); setDelimiterChar(delim); }
    public StrTokenizer(String input, String delim)     { this(input); setDelimiterString(delim); }
    public StrTokenizer(String input, StrMatcher delim) { this(input); setDelimiterMatcher(delim); }
    public StrTokenizer(String input, char delim, char quote) { this(input, delim); setQuoteChar(quote); }
    public StrTokenizer(String input, StrMatcher delim, StrMatcher quote) { this(input, delim); setQuoteMatcher(quote); }

    public StrTokenizer(char[] input)                   { super(); this.chars = input; }
    public StrTokenizer(char[] input, char delim)       { this(input); setDelimiterChar(delim); }
    public StrTokenizer(char[] input, String delim)     { this(input); setDelimiterString(delim); }
    public StrTokenizer(char[] input, StrMatcher delim) { this(input); setDelimiterMatcher(delim); }
    public StrTokenizer(char[] input, char delim, char quote) { this(input, delim); setQuoteChar(quote); }
    public StrTokenizer(char[] input, StrMatcher delim, StrMatcher quote) { this(input, delim); setQuoteMatcher(quote); }

    // API
    //-----------------------------------------------------------------------
    public String nextToken()     { if (hasNext()) { return tokens[tokenPos++]; } return null; }
    public String previousToken() { if (hasPrevious()) { return tokens[--tokenPos]; } return null; }
    public String[] getTokenArray() { checkTokenized(); return (String[]) tokens.clone(); }
    public List getTokenList() {
        checkTokenized();
        List list = new ArrayList(tokens.length);
        for (int i = 0; i < tokens.length; i++) {
            list.add(tokens[i]);
        }
        return list;
    }
    /** Gets the number of tokens found in the String. */
    public int size() { checkTokenized(); return tokens.length; }

    /** Resets this tokenizer, forgetting all parsing and iteration already completed.
     * This method allows the same tokenizer to be reused for the same String. */
    public StrTokenizer reset() { tokenPos = 0; tokens = null; return this; }
    public StrTokenizer reset(char[] input) { reset(); this.chars = input; return this; }
    public StrTokenizer reset(String input) { reset(); chars = input != null ? input.toCharArray() : null; return this; }

    // -- ListIterator --
    public boolean hasNext()     { checkTokenized(); return tokenPos < tokens.length; }
    public boolean hasPrevious() { checkTokenized(); return tokenPos > 0; }
    public int nextIndex()      { return tokenPos; }
    public int previousIndex()  { return tokenPos - 1; }
    public Object next() { if (hasNext()) { return tokens[tokenPos++]; } throw new NoSuchElementException(); }
    public Object previous() { if (hasPrevious()) { return tokens[--tokenPos]; } throw new NoSuchElementException(); }
    public void remove() { throw new UnsupportedOperationException("unsupported"); }
    public void set(Object obj) { throw new UnsupportedOperationException("unsupported"); }
    public void add(Object obj) { throw new UnsupportedOperationException("unsupported"); }

    // -- Implementation --
    /** Checks if tokenization has been done, and if not then do it. */
    private void checkTokenized() {
        if (tokens == null) {
            if (chars == null) {
                // still call tokenize as subclass may do some work
                List split = tokenize(null, 0, 0);
                tokens = (String[]) split.toArray(new String[split.size()]);
            } else {
                List split = tokenize(chars, 0, chars.length);
                tokens = (String[]) split.toArray(new String[split.size()]);
            }
        }
    }

    /** Internal method to performs the tokenization.
     * Most users of this class do not need to call this method. This method
     * will be called automatically by other (public) methods when required.
     * This method exists to allow subclasses to add code before or after the
     * tokenization. For example, a subclass could alter the character array,
     * offset or count to be parsed, or call the tokenizer multiple times on
     * multiple strings. It is also be possible to filter the results.
     * <code>StrTokenizer</code> will always pass a zero offset and a count
     * equal to the length of the array to this method, however a subclass
     * may pass other values, or even an entirely different array.
     * @param chars  the character array being tokenized, may be null
     * @param offset  the start position within the character array, must be valid
     * @param count  the number of characters to tokenize, must be valid
     * @return the modifiable list of String tokens, unmodifiable if null array or zero count */
    protected List tokenize(char[] chars, int offset, int count) {
        if (chars == null || count == 0) {
            return Collections.EMPTY_LIST;
        }
        StrBuilder buf = new StrBuilder();
        List tokens = new ArrayList();
        int pos = offset;
        
        // loop around the entire buffer
        while (pos >= 0 && pos < count) {
            // find next token
            pos = readNextToken(chars, pos, count, buf, tokens);
            
            // handle case where end of string is a delimiter
            if (pos >= count) {
                addToken(tokens, "");
            }
        }
        return tokens;
    }

    /** Adds a token to a list, paying attention to the parameters we've set. */
    private void addToken(List list, String tok) {
        if (tok == null || tok.length() == 0) {
            if (isIgnoreEmptyTokens()) {
                return;
            }
            if (isEmptyTokenAsNull()) {
                tok = null;
            }
        }
        list.add(tok);
    }

    /** Reads character by character through the String to get the next token.
     * @param chars  the character array being tokenized
     * @param start  the first character of field
     * @param len  the length of the character array being tokenized
     * @param workArea  a temporary work area
     * @param tokens  the list of parsed tokens
     * @return the starting position of the next field (the character
     *  immediately after the delimiter), or -1 if end of string found */
    private int readNextToken(char[] chars, int start, int len, StrBuilder workArea, List tokens) {
        // skip all leading whitespace, unless it is the
        // field delimiter or the quote character
        while (start < len) {
            int removeLen = Math.max(
                    getIgnoredMatcher().isMatch(chars, start, start, len),
                    getTrimmerMatcher().isMatch(chars, start, start, len));
            if (removeLen == 0 ||
                getDelimiterMatcher().isMatch(chars, start, start, len) > 0 ||
                getQuoteMatcher().isMatch(chars, start, start, len) > 0) {
                break;
            }
            start += removeLen;
        }
        
        // handle reaching end
        if (start >= len) {
            addToken(tokens, "");
            return -1;
        }
        
        // handle empty token
        int delimLen = getDelimiterMatcher().isMatch(chars, start, start, len);
        if (delimLen > 0) {
            addToken(tokens, "");
            return start + delimLen;
        }
        
        // handle found token
        int quoteLen = getQuoteMatcher().isMatch(chars, start, start, len);
        if (quoteLen > 0) {
            return readWithQuotes(chars, start + quoteLen, len, workArea, tokens, start, quoteLen);
        }
        return readWithQuotes(chars, start, len, workArea, tokens, 0, 0);
    }

    /** Reads a possibly quoted string token.  */
    private int readWithQuotes(char[] chars, int start, int len, StrBuilder workArea, 
                               List tokens, int quoteStart, int quoteLen) {
        // Loop until we've found the end of the quoted
        // string or the end of the input
        workArea.clear();
        int pos = start;
        boolean quoting = (quoteLen > 0);
        int trimStart = 0;
        
        while (pos < len) {
            // quoting mode can occur several times throughout a string
            // we must switch between quoting and non-quoting until we
            // encounter a non-quoted delimiter, or end of string
            if (quoting) {
                // In quoting mode
                
                // If we've found a quote character, see if it's
                // followed by a second quote.  If so, then we need
                // to actually put the quote character into the token
                // rather than end the token.
                if (isQuote(chars, pos, len, quoteStart, quoteLen)) {
                    if (isQuote(chars, pos + quoteLen, len, quoteStart, quoteLen)) {
                        // matched pair of quotes, thus an escaped quote
                        workArea.append(chars, pos, quoteLen);
                        pos += (quoteLen * 2);
                        trimStart = workArea.size();
                        continue;
                    }
                    
                    // end of quoting
                    quoting = false;
                    pos += quoteLen;
                    continue;
                }
                
                // copy regular character from inside quotes
                workArea.append(chars[pos++]);
                trimStart = workArea.size();
                
            } else {
                // Not in quoting mode
                
                // check for delimiter, and thus end of token
                int delimLen = getDelimiterMatcher().isMatch(chars, pos, start, len);
                if (delimLen > 0) {
                    // return condition when end of token found
                    addToken(tokens, workArea.substring(0, trimStart));
                    return pos + delimLen;
                }
                
                // check for quote, and thus back into quoting mode
                if (quoteLen > 0) {
                    if (isQuote(chars, pos, len, quoteStart, quoteLen)) {
                        quoting = true;
                        pos += quoteLen;
                        continue;
                    }
                }
                
                // check for ignored (outside quotes), and ignore
                int ignoredLen = getIgnoredMatcher().isMatch(chars, pos, start, len);
                if (ignoredLen > 0) {
                    pos += ignoredLen;
                    continue;
                }
                
                // check for trimmed character
                // don't yet know if its at the end, so copy to workArea
                // use trimStart to keep track of trim at the end
                int trimmedLen = getTrimmerMatcher().isMatch(chars, pos, start, len);
                if (trimmedLen > 0) {
                    workArea.append(chars, pos, trimmedLen);
                    pos += trimmedLen;
                    continue;
                }
                
                // copy regular character from outside quotes
                workArea.append(chars[pos++]);
                trimStart = workArea.size();
            }
        }
        
        // return condition when end of string found
        addToken(tokens, workArea.substring(0, trimStart));
        return -1;
    }

    /** Checks if the characters at the index specified match the quote
     * already matched in readNextToken(). */
    private boolean isQuote(char[] chars, int pos, int len, int quoteStart, int quoteLen) {
        for (int i = 0; i < quoteLen; i++) {
            if ((pos + i) >= len || chars[pos + i] != chars[quoteStart + i]) {
                return false;
            }
        }
        return true;
    }

    // -- getters and setters --
    public StrMatcher getDelimiterMatcher() { return this.delimMatcher; }
    public StrTokenizer setDelimiterMatcher(StrMatcher delim) { this.delimMatcher = delim == null ? StrMatcher.noneMatcher() : delim; return this; }
    public StrTokenizer setDelimiterChar(char delim) { return setDelimiterMatcher(StrMatcher.charMatcher(delim)); }
    public StrTokenizer setDelimiterString(String delim) { return setDelimiterMatcher(StrMatcher.stringMatcher(delim)); }

    public StrMatcher getQuoteMatcher() { return quoteMatcher; }
    public StrTokenizer setQuoteMatcher(StrMatcher quote) { if (quote != null) { this.quoteMatcher = quote; } return this; }
    public StrTokenizer setQuoteChar(char quote) { return setQuoteMatcher(StrMatcher.charMatcher(quote)); } 

    public StrMatcher getIgnoredMatcher() { return ignoredMatcher; }
    public StrTokenizer setIgnoredMatcher(StrMatcher ignored) { if (ignored != null) { this.ignoredMatcher = ignored; } return this; }
    public StrTokenizer setIgnoredChar(char ignored) { return setIgnoredMatcher(StrMatcher.charMatcher(ignored)); }

    public StrMatcher getTrimmerMatcher() { return trimmerMatcher; }
    public StrTokenizer setTrimmerMatcher(StrMatcher trimmer) { if (trimmer != null) { this.trimmerMatcher = trimmer; } return this; }

    public boolean isEmptyTokenAsNull() { return this.emptyAsNull; }
    public StrTokenizer setEmptyTokenAsNull(boolean emptyAsNull) { this.emptyAsNull = emptyAsNull; return this; }

    public boolean isIgnoreEmptyTokens() { return ignoreEmptyTokens; }
    public StrTokenizer setIgnoreEmptyTokens(boolean ignoreEmptyTokens) { this.ignoreEmptyTokens = ignoreEmptyTokens; return this; }

    public String getContent() { return chars == null ? null : new String(chars); }

    public Object clone() {
        try {
            return cloneReset();
        } catch (CloneNotSupportedException ex) {
            return null;
        }
    }
    Object cloneReset() throws CloneNotSupportedException {
        // this method exists to enable 100% test coverage
        StrTokenizer cloned = (StrTokenizer) super.clone();
        if (cloned.chars != null) {
            cloned.chars = (char[]) cloned.chars.clone();
        }
        cloned.reset();
        return cloned;
    }
}
